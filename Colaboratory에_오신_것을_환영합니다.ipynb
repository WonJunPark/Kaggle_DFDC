{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colaboratory에 오신 것을 환영합니다",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonJunPark/Kaggle_DFDC/blob/master/Colaboratory%EC%97%90_%EC%98%A4%EC%8B%A0_%EA%B2%83%EC%9D%84_%ED%99%98%EC%98%81%ED%95%A9%EB%8B%88%EB%8B%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPOpsgfkBYPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyjcudFBB1q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "work_root_path = \"/content/gdrive/My Drive/Kaggle/DFDC/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sGYIcE1B1tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmjNJdjkBYUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def read_img(path):\n",
        "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def shuffle(X,y):\n",
        "    new_train=[]\n",
        "    for m,n in zip(X,y):\n",
        "        new_train.append([m,n])\n",
        "    random.shuffle(new_train)\n",
        "    X,y=[],[]\n",
        "    for x in new_train:\n",
        "        X.append(x[0])\n",
        "        y.append(x[1])\n",
        "    return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tHC_fraBYZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y=[],[]\n",
        "\n",
        "real = os.listdir('/content/gdrive/My Drive/Kaggle/DFDC/dfdc_train_v1/real')\n",
        "\n",
        "for file in tqdm(real):\n",
        "  im = read_img(f'/content/gdrive/My Drive/Kaggle/DFDC/dfdc_train_v1/real/{file}')\n",
        "  im = cv2.resize(im, (150,150))\n",
        "  X.append(im)\n",
        "  y.append(0)\n",
        "\n",
        "fake = os.listdir('/content/gdrive/My Drive/Kaggle/DFDC/dfdc_train_v1/fake')\n",
        "\n",
        "for file in tqdm(real):\n",
        "  im = read_img(f'/content/gdrive/My Drive/Kaggle/DFDC/dfdc_train_v1/fake/{file}')\n",
        "  im = cv2.resize(im, (150,150))\n",
        "  X.append(im)\n",
        "  y.append(1)\n",
        "\n",
        "X, y = shuffle(X,y)\n",
        "val_X, val_y = shuffle(val_X,val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I66vGpJEz_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeiASOcEBYb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, X, y, training=True, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "        self.training = training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        img = self.X[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "          res = self.transform(image=img)\n",
        "          img = res['image']\n",
        "        \n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "        # img = np.array(img).astype(np.float32) / 255.\n",
        "\n",
        "        labels = self.y[idx]\n",
        "        labels = np.array(labels).astype(np.float32)\n",
        "        return [img, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I-cYYbFE0Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ZxiOUpE0i6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6b0cd4b1-8bc1-47ab-d5a4-b3f39f53afaf"
      },
      "source": [
        "!pip install pytorchcv --quiet\n",
        "from pytorchcv.model_provider import get_model\n",
        "model = get_model(\"xception\", pretrained=True)\n",
        "# model = get_model(\"resnet18\", pretrained=True)\n",
        "model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▉                               | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 399kB 2.8MB/s \n",
            "\u001b[?25hDownloading /root/.torch/models/xception-0549-e4f0232c.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.115/xception-0549-e4f0232c.pth.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmAZrr6pE0lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model[0].final_block.pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))\n",
        "# model[0].final_pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZx9s0KsE422",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Head(torch.nn.Module):\n",
        "  def __init__(self, in_f, out_f):\n",
        "    super(Head, self).__init__()\n",
        "    \n",
        "    self.f = nn.Flatten()\n",
        "    self.l = nn.Linear(in_f, 512)\n",
        "    self.d = nn.Dropout(0.75)\n",
        "    self.o = nn.Linear(512, out_f)\n",
        "    self.b1 = nn.BatchNorm1d(in_f)\n",
        "    self.b2 = nn.BatchNorm1d(512)\n",
        "    self.r = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.f(x)\n",
        "    x = self.b1(x)\n",
        "    x = self.d(x)\n",
        "\n",
        "    x = self.l(x)\n",
        "    x = self.r(x)\n",
        "    x = self.b2(x)\n",
        "    x = self.d(x)\n",
        "\n",
        "    out = self.o(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJXhc8O0E5DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCN(torch.nn.Module):\n",
        "  def __init__(self, base, in_f):\n",
        "    super(FCN, self).__init__()\n",
        "    self.base = base\n",
        "    self.h1 = Head(in_f, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.base(x)\n",
        "    return self.h1(x)\n",
        "\n",
        "model = FCN(model, 2048)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYflnvXEE5FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def criterion1(pred1, targets):\n",
        "  l1 = F.binary_cross_entropy(F.sigmoid(pred1), targets)\n",
        "  return l1\n",
        "\n",
        "def train_model(epoch, optimizer, scheduler=None, history=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    t = tqdm(train_loader)\n",
        "    for i, (img_batch, y_batch) in enumerate(t):\n",
        "        img_batch = img_batch.cuda().float()\n",
        "        y_batch = y_batch.cuda().float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(img_batch)\n",
        "        loss = criterion1(out, y_batch)\n",
        "\n",
        "        total_loss += loss\n",
        "        t.set_description(f'Epoch {epoch+1}/{n_epochs}, LR: %6f, Loss: %.4f'%(optimizer.state_dict()['param_groups'][0]['lr'],total_loss/(i+1)))\n",
        "\n",
        "        if history is not None:\n",
        "          history.loc[epoch + i / len(X), 'train_loss'] = loss.data.cpu().numpy()\n",
        "          history.loc[epoch + i / len(X), 'lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "\n",
        "def evaluate_model(epoch, scheduler=None, history=None):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    pred = []\n",
        "    real = []\n",
        "    with torch.no_grad():\n",
        "        for img_batch, y_batch in val_loader:\n",
        "            img_batch = img_batch.cuda().float()\n",
        "            y_batch = y_batch.cuda().float()\n",
        "\n",
        "            o1 = model(img_batch)\n",
        "            l1 = criterion1(o1, y_batch)\n",
        "            loss += l1\n",
        "            \n",
        "            for j in o1:\n",
        "              pred.append(F.sigmoid(j))\n",
        "            for i in y_batch:\n",
        "              real.append(i.data.cpu())\n",
        "    \n",
        "    pred = [p.data.cpu().numpy() for p in pred]\n",
        "    pred2 = pred\n",
        "    pred = [np.round(p) for p in pred]\n",
        "    pred = np.array(pred)\n",
        "    acc = sklearn.metrics.recall_score(real, pred, average='macro')\n",
        "\n",
        "    real = [r.item() for r in real]\n",
        "    pred2 = np.array(pred2).clip(0.1, 0.9)\n",
        "    kaggle = sklearn.metrics.log_loss(real, pred2)\n",
        "\n",
        "    loss /= len(val_loader)\n",
        "    \n",
        "    if history is not None:\n",
        "        history.loc[epoch, 'dev_loss'] = loss.cpu().numpy()\n",
        "    \n",
        "    if scheduler is not None:\n",
        "      scheduler.step(loss)\n",
        "\n",
        "    print(f'Dev loss: %.4f, Acc: %.6f, Kaggle: %.6f'%(loss,acc,kaggle))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obqFBBY8FED7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKkHrvhuE5Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations\n",
        "from albumentations.augmentations.transforms import ShiftScaleRotate, HorizontalFlip, Normalize, RandomBrightnessContrast, MotionBlur, Blur, GaussNoise, JpegCompression\n",
        "train_transform = albumentations.Compose([\n",
        "                                          ShiftScaleRotate(p=0.3, scale_limit=0.25, border_mode=1, rotate_limit=25),\n",
        "                                          HorizontalFlip(p=0.2),\n",
        "                                          RandomBrightnessContrast(p=0.3, brightness_limit=0.25, contrast_limit=0.5),\n",
        "                                          MotionBlur(p=.2),\n",
        "                                          GaussNoise(p=.2),\n",
        "                                          JpegCompression(p=.2, quality_lower=50),\n",
        "                                          Normalize()\n",
        "])\n",
        "val_transform = albumentations.Compose([\n",
        "                                          Normalize()\n",
        "])\n",
        "\n",
        "train_dataset = ImageDataset(X, y, transform=train_transform)\n",
        "val_dataset = ImageDataset(val_X, val_y, transform=val_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtOVKYnbE5Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nrow, ncol = 5, 6\n",
        "fig, axes = plt.subplots(nrow, ncol, figsize=(20, 8))\n",
        "axes = axes.flatten()\n",
        "for i, ax in enumerate(axes):\n",
        "    image, label = train_dataset[i]\n",
        "    image = np.rollaxis(image, 0, 3)\n",
        "    image = image*std + mean\n",
        "    image = np.clip(image, 0., 1.)\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(f'label: {label}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-UbH7PGFDu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR1eWopHFEgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "history = pd.DataFrame()\n",
        "history2 = pd.DataFrame()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best = 1e10\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, mode='min', factor=0.7, verbose=True, min_lr=1e-5)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    train_model(epoch, optimizer, scheduler=None, history=history)\n",
        "    \n",
        "    loss = evaluate_model(epoch, scheduler=scheduler, history=history2)\n",
        "    \n",
        "    if loss < best:\n",
        "      best = loss\n",
        "      print(f'Saving best model...')\n",
        "      torch.save(model.state_dict(), f'model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsQ57wkYFEif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}