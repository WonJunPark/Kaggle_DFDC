{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKn8MXZ3RpyUFpEJ11bvzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonJunPark/img_recog/blob/master/Xception_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOKcSSCqU0rG",
        "colab_type": "text"
      },
      "source": [
        "# Xception Classifier w/ FFHQ - Training - LB: .555"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLAWTs0SBXI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "※ 본 커널은 캐글에 공유된 https://www.kaggle.com/greatgamedota/xception-classifier-w-ffhq-training-lb-537 의 내용을 기반으로 작성되었습니다.\n",
        "\n",
        "※ 커널 정리 방식은 문성채 선생님의 커널을 참고하여 구성해보았습니다. 감사합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6fWEDr6VEex",
        "colab_type": "text"
      },
      "source": [
        "# Colab 사용을 위한 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbprBIqCTTRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_colab = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptyGdTXuVMRd",
        "colab_type": "code",
        "outputId": "02b1e0cd-e657-4622-f61c-2f66703d0ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if use_colab == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnAqVbTMVe0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_colab == True:\n",
        "  work_root_path = \"/content/gdrive/My Drive/Kaggle/DFDC2/\"\n",
        "else:\n",
        "  work_root_path = \"../\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axv9SJA4Vs9J",
        "colab_type": "code",
        "outputId": "84b2647c-ae17-4ed4-ffda-a83a0301c7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/content/gdrive/My Drive\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI9vag-RVxdh",
        "colab_type": "text"
      },
      "source": [
        "# Simple baseline binary classifier using FFHQ dataset to balance the data\n",
        "\n",
        "- 이 커널은 Xception Classifier에 FFHQ dataset을 추가로 학습시킵니다.\n",
        "\n",
        "- https://github.com/NVlabs/ffhq-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKN0LTXpWi0M",
        "colab_type": "text"
      },
      "source": [
        "# 1 Common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkQfge66WrWp",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmz3xYkFWY6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXTYec60lHLU",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Prepare and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37OepJd4X86k",
        "colab_type": "code",
        "outputId": "b9a57c79-6239-4dba-909f-e396b4dfc336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/content/gdrive/My Drive/Kaggle/DFDC2/input\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle/DFDC2/input\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATD7AQ43Xz0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = []\n",
        "\n",
        "# total = 50\n",
        "df_train_num = 47   # 0~46\n",
        "df_val_num = 3      # 47~49\n",
        "\n",
        "df_trains = []\n",
        "df_vals = []\n",
        "\n",
        "for i in range(df_train_num):\n",
        "  s = work_root_path+'input/metadata'+ str(i) +'.json'\n",
        "  deepfake = pd.read_json(s)\n",
        "  df_trains.append(deepfake)\n",
        "\n",
        "for i in range(df_val_num):\n",
        "  s = work_root_path+'input/metadata'+ str(df_train_num + i) +'.json'\n",
        "  deepfake = pd.read_json(s)\n",
        "  df_vals.append(deepfake)\n",
        "\n",
        "nums = list(range(len(df_trains)+1))\n",
        "LABELS = ['REAL','FAKE']\n",
        "val_nums=[47, 48, 49]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va-IcEo1qQHZ",
        "colab_type": "code",
        "outputId": "1f0c4ba5-30b7-472a-b91b-3813d19b3c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_trains"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[          owxbbpjpch.mp4 vpmyeepbep.mp4  ...  fonrexmbzz.mp4  etychryvty.mp4\n",
              " label               FAKE           REAL  ...            FAKE            FAKE\n",
              " split              train          train  ...           train           train\n",
              " original  wynotylpnm.mp4            NaN  ...  fufcmupzen.mp4  uqtqhiqymz.mp4\n",
              " \n",
              " [3 rows x 1334 columns],\n",
              "           zumqqvixhu.mp4  utdlsqfykm.mp4  ...  bfeewgzrbr.mp4  tovxgyattq.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  hntguogkqd.mp4  nswtvttxre.mp4  ...  qjdtgggqym.mp4  hjhdhumvod.mp4\n",
              " \n",
              " [3 rows x 1699 columns],\n",
              "           qyyebirxwe.mp4  ntjlknlcvn.mp4  ...  sdibedfnep.mp4 oovzfmploa.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  ejhhokmvpe.mp4  nthpnwylxo.mp4  ...  fqvaalcdae.mp4            NaN\n",
              " \n",
              " [3 rows x 1748 columns],\n",
              "           vngueqqcmz.mp4  ieblyetiob.mp4  ... hwaxcxpfxl.mp4 iutieugpqx.mp4\n",
              " label               FAKE            FAKE  ...           REAL           REAL\n",
              " split              train           train  ...          train          train\n",
              " original  ghfnznqrvh.mp4  tsvhwitvah.mp4  ...            NaN            NaN\n",
              " \n",
              " [3 rows x 1455 columns],\n",
              "           oyixebfpcl.mp4 sayyjwtjol.mp4  ... aahncigwte.mp4  jdnizohssx.mp4\n",
              " label               FAKE           REAL  ...           REAL            FAKE\n",
              " split              train          train  ...          train           train\n",
              " original  bgpoldvzrh.mp4            NaN  ...            NaN  xxbunqmupn.mp4\n",
              " \n",
              " [3 rows x 1701 columns],\n",
              "           syybbzdttf.mp4  ibyevudtta.mp4  ...  ouyjjhlatg.mp4  mdpkidzzlm.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  gmkfzogjlj.mp4  xfrswzqrmn.mp4  ...  ayfohzyelj.mp4  gwmlawcreb.mp4\n",
              " \n",
              " [3 rows x 2483 columns],\n",
              "           olczadekwi.mp4  xehgproyja.mp4  ... spsevdcrnu.mp4  xeiopfasdx.mp4\n",
              " label               FAKE            FAKE  ...           REAL            FAKE\n",
              " split              train           train  ...          train           train\n",
              " original  enjaxrsqfw.mp4  eaigdemyfo.mp4  ...            NaN  opzchpdtfl.mp4\n",
              " \n",
              " [3 rows x 3464 columns],\n",
              "           laihwpwiee.mp4  kzkqjyioqf.mp4  ...  oavrralgxd.mp4  qurcxbznni.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  aeysrmfmht.mp4  ighgptshjh.mp4  ...  mbxblocpyw.mp4  rstlwzctdt.mp4\n",
              " \n",
              " [3 rows x 2473 columns],\n",
              "           kadarrfhjj.mp4  ucqxtucqva.mp4  ...  ljjoeunhkt.mp4  ouqpnjoshj.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  vsbrghzshm.mp4  ioqacgyrwh.mp4  ...  sojxeyjdat.mp4  lycgrrymbx.mp4\n",
              " \n",
              " [3 rows x 1816 columns],\n",
              "           jgaejvfomy.mp4  yaroumkbcf.mp4  ...  wadgdooqpl.mp4  wwwbocaabd.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  zqfntxsnna.mp4  dnocqlgupe.mp4  ...  mhpavogfxb.mp4  icffpvvtnu.mp4\n",
              " \n",
              " [3 rows x 1736 columns],\n",
              "           hsypgwsufp.mp4  ntzgbkzofo.mp4  ... bkwicglevl.mp4  gdhlrzpxxr.mp4\n",
              " label               FAKE            FAKE  ...           REAL            FAKE\n",
              " split              train           train  ...          train           train\n",
              " original  nbnipejygk.mp4  cqlarprtdy.mp4  ...            NaN  qgfxkgofjl.mp4\n",
              " \n",
              " [3 rows x 3192 columns],\n",
              "           qgqsgtekwl.mp4  bahpguunin.mp4  ...  rgmllhylbj.mp4 ddhijrstzr.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  ztutsnlhtr.mp4  frczmdfzza.mp4  ...  usnyozppis.mp4            NaN\n",
              " \n",
              " [3 rows x 2118 columns],\n",
              "           ufucquemsr.mp4  hzpeccyres.mp4  ...  oexoavedkb.mp4 hmurwmhvsz.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  ioxuwhhvge.mp4  guupwbnbzc.mp4  ...  zgvjfpzubp.mp4            NaN\n",
              " \n",
              " [3 rows x 2225 columns],\n",
              "           wxiboojdnq.mp4  ojdrqflslr.mp4  ...  radyyavwaa.mp4  zglgidpizh.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  vncfwkhxmd.mp4  yaivbfubpr.mp4  ...  galckcdeka.mp4  sianpqcthw.mp4\n",
              " \n",
              " [3 rows x 3694 columns],\n",
              "           fmdhqnkvyo.mp4  eeubskpxct.mp4  ... vqrvgctzdi.mp4 uvuqozqxqt.mp4\n",
              " label               FAKE            FAKE  ...           REAL           REAL\n",
              " split              train           train  ...          train          train\n",
              " original  filuudleua.mp4  hdunuumyxa.mp4  ...            NaN            NaN\n",
              " \n",
              " [3 rows x 2464 columns],\n",
              "           sgleazzkwf.mp4  tulxkqjvty.mp4  ...  ucahnqkqim.mp4  ofnmctcjma.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  hdfhmlsrzn.mp4  ezuftudsoa.mp4  ...  uyghebrnju.mp4  uyghebrnju.mp4\n",
              " \n",
              " [3 rows x 2273 columns],\n",
              "           rfpjvmqzre.mp4  icwlmhflzf.mp4  ...  afrgmowivl.mp4  wsfwysxlsf.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  jcdwcvhiic.mp4  bmrwcqrpyp.mp4  ...  frbhfojsry.mp4  ncrwgivkxi.mp4\n",
              " \n",
              " [3 rows x 2061 columns],\n",
              "          rnzzuxmigr.mp4  gpwnvzdflz.mp4  ...  isshcjsmlj.mp4  nkhskoelyv.mp4\n",
              " label              REAL            FAKE  ...            FAKE            FAKE\n",
              " split             train           train  ...           train           train\n",
              " original            NaN  kecpjuvcti.mp4  ...  bzcolqetwd.mp4  tzftvixuzs.mp4\n",
              " \n",
              " [3 rows x 2430 columns],\n",
              "           iueofqnitn.mp4  vcbgvdnvlc.mp4  ... qawfrjdwud.mp4 annmtetkqa.mp4\n",
              " label               FAKE            FAKE  ...           REAL           REAL\n",
              " split              train           train  ...          train          train\n",
              " original  xatruuhtpv.mp4  duplyxsudb.mp4  ...            NaN            NaN\n",
              " \n",
              " [3 rows x 2686 columns],\n",
              "           pxleaiojzt.mp4  tlnearikan.mp4  ...  yofsgydgvx.mp4  fxsiohgbap.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  cymfsdestn.mp4  aqfjgahafl.mp4  ...  dzzcfvkgth.mp4  qzkzkxdvva.mp4\n",
              " \n",
              " [3 rows x 2752 columns],\n",
              "           dvglijlzdi.mp4  izwsybqjfz.mp4  ...  etqegkhtlt.mp4 zxunnxrvpf.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  mwlwlieswy.mp4  xqsivexncg.mp4  ...  cphfdjkgmq.mp4            NaN\n",
              " \n",
              " [3 rows x 2154 columns],\n",
              "           xumudadztd.mp4  sjrpypsiyt.mp4  ...  sppcmqfihc.mp4 vcxejqfdim.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  jsddeswcrn.mp4  owhhlfbyqd.mp4  ...  enjzkucxsd.mp4            NaN\n",
              " \n",
              " [3 rows x 2268 columns],\n",
              "           vkketnrfud.mp4  tnsaqegyqt.mp4  ...  kmrjhsbqqy.mp4  edszrezley.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  ygcrqskjni.mp4  nhkenclutb.mp4  ...  fgrxodoqcr.mp4  nirwqaczoe.mp4\n",
              " \n",
              " [3 rows x 2409 columns],\n",
              "           ptfpxubayi.mp4  uvqiaycegp.mp4  ...  ryevadcshl.mp4  myrrisyzya.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  xqpxxtnryn.mp4  ooswfaxrxx.mp4  ...  zpompmamlx.mp4  tmadjtypjv.mp4\n",
              " \n",
              " [3 rows x 2410 columns],\n",
              "           anijjqtfth.mp4  zffofixoeh.mp4  ...  ieybeoxyyd.mp4  etisprvjae.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  qbwwpvgyhh.mp4  bjdtgkmvza.mp4  ...  gstyhbnxwx.mp4  vcwjvigiyf.mp4\n",
              " \n",
              " [3 rows x 2786 columns],\n",
              "           nbgepetpyw.mp4  gcxwoablgs.mp4  ...  dulqhllfov.mp4 nqvbdzixhe.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  zxvhssxqza.mp4  vywtjgalte.mp4  ...  zmfjyoofct.mp4            NaN\n",
              " \n",
              " [3 rows x 2546 columns],\n",
              "           yojgjueqta.mp4  xnzhlgindk.mp4  ...  mptpnkfudq.mp4  xicfancdrx.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  gpdtoamvkz.mp4  ivlxgbadrs.mp4  ...  qpttgwtqxo.mp4  glwlzersek.mp4\n",
              " \n",
              " [3 rows x 2433 columns],\n",
              "           uxnhxyippv.mp4  ywpwcqmabi.mp4  ...  djumgpchrn.mp4  glfmswucsj.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  susbqdbdij.mp4  bwdagcnaix.mp4  ...  umaapupckb.mp4  lhnoolzvoa.mp4\n",
              " \n",
              " [3 rows x 2353 columns],\n",
              "           jrvjswdnbj.mp4  atyntldecu.mp4  ...  gogdodtvfw.mp4  chzieimrwu.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  ehtdtkmmli.mp4  mfzqxktxud.mp4  ...  ddepeddixj.mp4  topyiohccg.mp4\n",
              " \n",
              " [3 rows x 2085 columns],\n",
              "           vqnsrcmsjc.mp4  lopgfogzkx.mp4  ...  xlmadlrzen.mp4  gskhaxrvap.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  bxgkydnxzv.mp4  wcgwcemzfg.mp4  ...  cqxwlkmiel.mp4  gvpoijxknl.mp4\n",
              " \n",
              " [3 rows x 2557 columns],\n",
              "           iuctpajxnn.mp4 rkflgbgcol.mp4  ... omhzxmlgqd.mp4  hkpbwybtfw.mp4\n",
              " label               FAKE           REAL  ...           REAL            FAKE\n",
              " split              train          train  ...          train           train\n",
              " original  jtnkppoigi.mp4            NaN  ...            NaN  omhzxmlgqd.mp4\n",
              " \n",
              " [3 rows x 2236 columns],\n",
              "           dgnijohvsx.mp4 gaxvondfff.mp4  ...  ujmnnaxuss.mp4 vlcjitqpjz.mp4\n",
              " label               FAKE           REAL  ...            FAKE           REAL\n",
              " split              train          train  ...           train          train\n",
              " original  kuzkknhjjw.mp4            NaN  ...  wcagdhcwxf.mp4            NaN\n",
              " \n",
              " [3 rows x 2470 columns],\n",
              "          cveqgferbf.mp4  dskhcyjnqw.mp4  ...  rjzzbkhgih.mp4  iclrzgdndu.mp4\n",
              " label              REAL            FAKE  ...            FAKE            FAKE\n",
              " split             train           train  ...           train           train\n",
              " original            NaN  mzmnjmwunq.mp4  ...  tzwywrsuvl.mp4  kynuygfmlh.mp4\n",
              " \n",
              " [3 rows x 2356 columns],\n",
              "           iqqejyggsm.mp4  xuymlytqyc.mp4  ...  ikbwuigstb.mp4  ohbwrsgvpz.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  gzesfubacw.mp4  kgsnfjekwa.mp4  ...  apobfcukea.mp4  ektqvjydep.mp4\n",
              " \n",
              " [3 rows x 2274 columns],\n",
              "           zhmjtavtpn.mp4  dazellwbsl.mp4  ... dawmxkceki.mp4  iwzxyrgxxx.mp4\n",
              " label               FAKE            FAKE  ...           REAL            FAKE\n",
              " split              train           train  ...          train           train\n",
              " original  ejnrxekehh.mp4  xuxkfhqjiu.mp4  ...            NaN  dawmxkceki.mp4\n",
              " \n",
              " [3 rows x 2658 columns],\n",
              "           auphqsoduh.mp4  vzuxewlhry.mp4  ...  kwjqhbnooe.mp4  irdvfgizvd.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  eofloyspbg.mp4  pqkigveluq.mp4  ...  gwmnzgwapx.mp4  nrujcvxszu.mp4\n",
              " \n",
              " [3 rows x 2540 columns],\n",
              "           dcoyfnrpsm.mp4  uqawzjjpre.mp4  ...  qxwmamefgj.mp4  qtmmzetbse.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  dzpychqarm.mp4  yxsettcask.mp4  ...  xtvcfygweu.mp4  igaobtaeuk.mp4\n",
              " \n",
              " [3 rows x 2339 columns],\n",
              "           xykwkrpmbo.mp4  axwvfkdsaq.mp4  ...  kgejshrtmz.mp4  qweglkmxpp.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  ntvjivuwes.mp4  iyxelmxpfx.mp4  ...  qtdyhcwdyi.mp4  mfofuymolr.mp4\n",
              " \n",
              " [3 rows x 2655 columns],\n",
              "           kmyhzsuequ.mp4  ebhmsikovp.mp4  ...  ajkrquvpzn.mp4  lyoglramoo.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  abhssqzhxu.mp4  nbmufxynnz.mp4  ...  fllccgwlhc.mp4  fllccgwlhc.mp4\n",
              " \n",
              " [3 rows x 2477 columns],\n",
              "           wqfjzcjbbz.mp4  egtrjvgggy.mp4  ... pgwvpgnoeq.mp4 oyiniibfdc.mp4\n",
              " label               FAKE            FAKE  ...           REAL           REAL\n",
              " split              train           train  ...          train          train\n",
              " original  qcohlfrfzb.mp4  iucnlyadlt.mp4  ...            NaN            NaN\n",
              " \n",
              " [3 rows x 2556 columns],\n",
              "           dkkqtmyitk.mp4 qyehiscxbr.mp4  ...  bqyybmnxmk.mp4  syyzlkofif.mp4\n",
              " label               FAKE           REAL  ...            FAKE            FAKE\n",
              " split              train          train  ...           train           train\n",
              " original  tkygmnaifp.mp4            NaN  ...  zukdhmubyy.mp4  xgqerzezcm.mp4\n",
              " \n",
              " [3 rows x 2420 columns],\n",
              "           bpunvjnbxu.mp4 myewuiruqd.mp4  ...  ijblnijmpp.mp4 taxjrcmkcz.mp4\n",
              " label               FAKE           REAL  ...            FAKE           REAL\n",
              " split              train          train  ...           train          train\n",
              " original  mkgbcumtar.mp4            NaN  ...  taxjrcmkcz.mp4            NaN\n",
              " \n",
              " [3 rows x 2222 columns],\n",
              "           tdmzwkhpha.mp4  lgqfanavff.mp4  ...  wfhyepctyv.mp4  cpvlmfudwa.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  vupmukvvxd.mp4  dnecilutfg.mp4  ...  lmvfpvnkmr.mp4  nybubisgar.mp4\n",
              " \n",
              " [3 rows x 2384 columns],\n",
              "           oltjahgizr.mp4  cqojknfuus.mp4  ...  zqlyovqwda.mp4  axkbdkcony.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  ivexyynvqc.mp4  aaapwqhxli.mp4  ...  kwqhorfuuv.mp4  xkspwcmsid.mp4\n",
              " \n",
              " [3 rows x 2546 columns],\n",
              "           szfifyvsso.mp4  ubmugwqfol.mp4  ...  exjmfjwuvn.mp4 raoksnpnna.mp4\n",
              " label               FAKE            FAKE  ...            FAKE           REAL\n",
              " split              train           train  ...           train          train\n",
              " original  wsxyuwcrfx.mp4  yadnjfpztj.mp4  ...  gyfqnutjyv.mp4            NaN\n",
              " \n",
              " [3 rows x 2665 columns],\n",
              "           gthvvygfcj.mp4  yunqitmhjo.mp4  ...  dmzbzcjsrg.mp4  jfjberuxhh.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  lxeqbyddvt.mp4  hbrgvmrtnn.mp4  ...  imsacxixmv.mp4  jygbqsigcr.mp4\n",
              " \n",
              " [3 rows x 2346 columns],\n",
              "           umkxoagtyp.mp4  icctbkjedq.mp4  ...  wddsnkeghb.mp4  iffowzafje.mp4\n",
              " label               FAKE            FAKE  ...            FAKE            FAKE\n",
              " split              train           train  ...           train           train\n",
              " original  ruhjnjwokl.mp4  gfdenskfme.mp4  ...  qufzdwetss.mp4  ngzqnucpqt.mp4\n",
              " \n",
              " [3 rows x 2202 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88eTSoFTlUSu",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdJJStvunqDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_path(num,x):\n",
        "    num=str(num)\n",
        "    if len(num)==2:\n",
        "        path= work_root_path + '/input/DeepFake'+num+'/DeepFake'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
        "    else:\n",
        "        path= work_root_path + '/input/DeepFake0'+num+'/DeepFake0'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
        "    if not os.path.exists(path):\n",
        "       raise Exception\n",
        "    return path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gshCHSZzYF9M",
        "colab_type": "code",
        "outputId": "fea2e2f0-f5df-4ec7-9315-019be7e7a85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Labeling\n",
        "# json 파일과 img 파일을 매칭\n",
        "paths=[]\n",
        "y=[]\n",
        "for df_train,num in tqdm(zip(df_trains,nums),total=len(df_trains)):\n",
        "    images = list(df_train.columns.values)\n",
        "    for x in images:\n",
        "        try:\n",
        "            paths.append(get_path(num,x))\n",
        "            y.append(LABELS.index(df_train[x]['label']))\n",
        "        except Exception as err:\n",
        "            #print(err)\n",
        "            pass\n",
        "\n",
        "val_paths=[]\n",
        "val_y=[]\n",
        "for df_val,num in tqdm(zip(df_vals,val_nums),total=len(df_vals)):\n",
        "    images = list(df_val.columns.values)\n",
        "    for x in images:\n",
        "        try:\n",
        "            val_paths.append(get_path(num,x))\n",
        "            val_y.append(LABELS.index(df_val[x]['label']))\n",
        "        except Exception as err:\n",
        "            #print(err)\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47/47 [12:52<00:00, 15.69s/it]\n",
            "100%|██████████| 3/3 [00:51<00:00, 17.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvrxk2iwwg-s",
        "colab_type": "code",
        "outputId": "dc75bed8-264a-4aa0-ddc9-55f52ece8a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('y : ',len(y))\n",
        "print('val_y :',len(val_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y :  104890\n",
            "val_y : 7366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_aj9GsyYF_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 컬러 이미지를 읽어오는 함수\n",
        "def read_img(path):\n",
        "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXsvwWxbYGCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X,y 데이터셋을 섞어줌\n",
        "def shuffle(X,y):\n",
        "    new_train=[]\n",
        "    for m,n in zip(X,y):\n",
        "        new_train.append([m,n])\n",
        "    random.shuffle(new_train)\n",
        "    X,y=[],[]\n",
        "    for x in new_train:\n",
        "        X.append(x[0])\n",
        "        y.append(x[1])\n",
        "    return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD5nBv1yYGFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def get_random_sampling(paths, y, val_paths, val_y):\n",
        "  real=[]\n",
        "  fake=[]\n",
        "  # train 데이터의 경로와 y값을 받아 real과 fake로 분류\n",
        "  for m,n in zip(paths,y):\n",
        "      if n==0:\n",
        "          real.append(m)\n",
        "      else:\n",
        "          fake.append(m)\n",
        "\n",
        "  # fake=random.sample(fake,len(real))\n",
        "  # paths list에 경로를 담고, y에 real과 fake 여부를 담음\n",
        "  # path와 y값을 매칭시켜 정리\n",
        "  paths,y=[],[]\n",
        "  for x in real:\n",
        "      paths.append(x)\n",
        "      y.append(0)\n",
        "  for x in fake:\n",
        "      paths.append(x)\n",
        "      y.append(1)\n",
        "\n",
        "  # validation 데이터도 위와 마찬가지로 real과 fake를 나누어줌\n",
        "  real=[]\n",
        "  fake=[]\n",
        "  for m,n in zip(val_paths,val_y):\n",
        "      if n==0:\n",
        "          real.append(m)\n",
        "      else:\n",
        "          fake.append(m)\n",
        "\n",
        "  # fake=random.sample(fake,len(real))\n",
        "  val_paths,val_y=[],[]\n",
        "  for x in real:\n",
        "      val_paths.append(x)\n",
        "      val_y.append(0)\n",
        "  for x in fake:\n",
        "      val_paths.append(x)\n",
        "      val_y.append(1)\n",
        "\n",
        "  # 경로안에 이미지를 불러옴\n",
        "  X=[]\n",
        "  for img in tqdm(paths):\n",
        "      X.append(read_img(img))\n",
        "  val_X=[]\n",
        "  for img in tqdm(val_paths):\n",
        "      val_X.append(read_img(img))\n",
        "\n",
        "\n",
        "  # ffhq 데이터 사용\n",
        "  # https://github.com/NVlabs/ffhq-dataset 에서 구글 드라이브로 공유\n",
        "  # Balance with ffhq dataset\n",
        "  ffhq = os.listdir('/content/gdrive/My Drive/thumbnails128x128')\n",
        "  X_ = []\n",
        "  # ffhq 데이터를 불러와 150*150으로 resize\n",
        "  # 해상도를 높이면 성능이 향상된다는 피드백이 있음\n",
        "  for file in tqdm(ffhq):\n",
        "    im = read_img(f'../input/ffhq-face-data-set/thumbnails128x128/{file}')\n",
        "    im = cv2.resize(im, (150,150))\n",
        "    X_.append(im)\n",
        "  random.shuffle(X_)\n",
        "\n",
        "  for i in range(64773 - 12130):\n",
        "    X.append(X_[i])\n",
        "    y.append(0)\n",
        "  del X_[0:64773 - 12130]\n",
        "  for i in range(6108 - 1258):\n",
        "    val_X.append(X_[i])\n",
        "    val_y.append(0)\n",
        "\n",
        "  X, y = shuffle(X,y)\n",
        "  val_X, val_y = shuffle(val_X,val_y)\n",
        "\n",
        "  return X, val_X, y, val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iitqwq0txUCm",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMrxgPLPYGIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, X, y, training=True, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "        self.training = training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        img = self.X[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "          res = self.transform(image=img)\n",
        "          img = res['image']\n",
        "        \n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "        # img = np.array(img).astype(np.float32) / 255.\n",
        "\n",
        "        labels = self.y[idx]\n",
        "        labels = np.array(labels).astype(np.float32)\n",
        "        return [img, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cAX4g8yxgSt",
        "colab_type": "text"
      },
      "source": [
        "# 2 Xception Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsKv3WZXx9Bv",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Xception Model Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGd3YwQ4wTsH",
        "colab_type": "code",
        "outputId": "69ea62b3-2c53-4fe9-be3f-3f21daedaae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!pip install pytorchcv --quiet\n",
        "from pytorchcv.model_provider import get_model\n",
        "model = get_model(\"xception\", pretrained=True)\n",
        "# model = get_model(\"resnet18\", pretrained=True)\n",
        "model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▉                               | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 399kB 2.7MB/s \n",
            "\u001b[?25hDownloading /root/.torch/models/xception-0549-e4f0232c.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.115/xception-0549-e4f0232c.pth.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhZe_IVQwTu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model[0].final_block.pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))\n",
        "# model[0].final_pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSbR--YwyOKd",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Model Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj5_SoxKyERH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Head(torch.nn.Module):\n",
        "  def __init__(self, in_f, out_f):\n",
        "    super(Head, self).__init__()\n",
        "    \n",
        "    self.f = nn.Flatten()\n",
        "    self.l = nn.Linear(in_f, 512)\n",
        "    self.d = nn.Dropout(0.75)\n",
        "    self.o = nn.Linear(512, out_f)\n",
        "    self.b1 = nn.BatchNorm1d(in_f)\n",
        "    self.b2 = nn.BatchNorm1d(512)\n",
        "    self.r = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.f(x)\n",
        "    x = self.b1(x)\n",
        "    x = self.d(x)\n",
        "\n",
        "    x = self.l(x)\n",
        "    x = self.r(x)\n",
        "    x = self.b2(x)\n",
        "    x = self.d(x)\n",
        "\n",
        "    out = self.o(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Kw5dRhyI9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCN(torch.nn.Module):\n",
        "  def __init__(self, base, in_f):\n",
        "    super(FCN, self).__init__()\n",
        "    self.base = base\n",
        "    self.h1 = Head(in_f, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.base(x)\n",
        "    return self.h1(x)\n",
        "\n",
        "model = FCN(model, 2048)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CH_L3asyI_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install torchtoolbox --quiet\n",
        "# from torchtoolbox.tools import summary\n",
        "\n",
        "# model.cuda()\n",
        "# summary(model, torch.rand((1, 3, 150, 150)).cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3FeuxEyyZr-",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Train Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLtxMDCLyJCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def criterion1(pred1, targets):\n",
        "  l1 = F.binary_cross_entropy(F.sigmoid(pred1), targets)\n",
        "  return l1\n",
        "\n",
        "def train_model(epoch, optimizer, scheduler=None, history=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    t = tqdm(train_loader)\n",
        "    for i, (img_batch, y_batch) in enumerate(t):\n",
        "        img_batch = img_batch.cuda().float()\n",
        "        y_batch = y_batch.cuda().float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(img_batch)\n",
        "        loss = criterion1(out, y_batch)\n",
        "\n",
        "        total_loss += loss\n",
        "        t.set_description(f'Epoch {epoch+1}/{n_epochs}, LR: %6f, Loss: %.4f'%(optimizer.state_dict()['param_groups'][0]['lr'],total_loss/(i+1)))\n",
        "\n",
        "        if history is not None:\n",
        "          history.loc[epoch + i / len(X), 'train_loss'] = loss.data.cpu().numpy()\n",
        "          history.loc[epoch + i / len(X), 'lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "\n",
        "def evaluate_model(epoch, scheduler=None, history=None):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    pred = []\n",
        "    real = []\n",
        "    with torch.no_grad():\n",
        "        for img_batch, y_batch in val_loader:\n",
        "            img_batch = img_batch.cuda().float()\n",
        "            y_batch = y_batch.cuda().float()\n",
        "\n",
        "            o1 = model(img_batch)\n",
        "            l1 = criterion1(o1, y_batch)\n",
        "            loss += l1\n",
        "            \n",
        "            for j in o1:\n",
        "              pred.append(F.sigmoid(j))\n",
        "            for i in y_batch:\n",
        "              real.append(i.data.cpu())\n",
        "    \n",
        "    pred = [p.data.cpu().numpy() for p in pred]\n",
        "    pred2 = pred\n",
        "    pred = [np.round(p) for p in pred]\n",
        "    pred = np.array(pred)\n",
        "    acc = sklearn.metrics.recall_score(real, pred, average='macro')\n",
        "\n",
        "    real = [r.item() for r in real]\n",
        "    pred2 = np.array(pred2).clip(0.1, 0.9)\n",
        "    kaggle = sklearn.metrics.log_loss(real, pred2)\n",
        "\n",
        "    loss /= len(val_loader)\n",
        "    \n",
        "    if history is not None:\n",
        "        history.loc[epoch, 'dev_loss'] = loss.cpu().numpy()\n",
        "    \n",
        "    if scheduler is not None:\n",
        "      scheduler.step(loss)\n",
        "\n",
        "    print(f'Dev loss: %.4f, Acc: %.6f, Kaggle: %.6f'%(loss,acc,kaggle))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QogWOSqAyzCl",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQEAJ9Iky270",
        "colab_type": "code",
        "outputId": "a2e428af-3e5f-4319-dc91-39fa01141f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "X, val_X, y, val_y = get_random_sampling(paths, y, val_paths, val_y)\n",
        "\n",
        "print('There are '+str(y.count(1))+' fake train samples')\n",
        "print('There are '+str(y.count(0))+' real train samples')\n",
        "print('There are '+str(val_y.count(1))+' fake val samples')\n",
        "print('There are '+str(val_y.count(0))+' real val samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 104890/104890 [5:49:27<00:00,  6.05it/s]\n",
            "100%|██████████| 7366/7366 [32:06<00:00,  6.54it/s]\n",
            "  0%|          | 0/71 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-824bcb245848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' fake train samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' real train samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' fake val samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-b74199036f47>\u001b[0m in \u001b[0;36mget_random_sampling\u001b[0;34m(paths, y, val_paths, val_y)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;31m# 해상도를 높이면 성능이 향상된다는 피드백이 있음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffhq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../input/ffhq-face-data-set/thumbnails128x128/{file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-65653fdd26d0>\u001b[0m in \u001b[0;36mread_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7lWItNYyY-4",
        "colab_type": "code",
        "outputId": "8fc6d561-e3c6-41bd-8248-dfc9120b0400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "import albumentations\n",
        "from albumentations.augmentations.transforms import ShiftScaleRotate, HorizontalFlip, Normalize, RandomBrightnessContrast, MotionBlur, Blur, GaussNoise, JpegCompression\n",
        "train_transform = albumentations.Compose([\n",
        "                                          ShiftScaleRotate(p=0.3, scale_limit=0.25, border_mode=1, rotate_limit=25),\n",
        "                                          HorizontalFlip(p=0.2),\n",
        "                                          RandomBrightnessContrast(p=0.3, brightness_limit=0.25, contrast_limit=0.5),\n",
        "                                          MotionBlur(p=.2),\n",
        "                                          GaussNoise(p=.2),\n",
        "                                          JpegCompression(p=.2, quality_lower=50),\n",
        "                                          Normalize()\n",
        "])\n",
        "val_transform = albumentations.Compose([\n",
        "                                          Normalize()\n",
        "])\n",
        "\n",
        "train_dataset = ImageDataset(X, y, transform=train_transform)\n",
        "val_dataset = ImageDataset(val_X, val_y, transform=val_transform)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-7b72f76e1e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYOjmmEgyZB2",
        "colab_type": "code",
        "outputId": "f2ecf1a4-7e51-4eb7-a03a-40f357d51a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "nrow, ncol = 5, 6\n",
        "fig, axes = plt.subplots(nrow, ncol, figsize=(20, 8))\n",
        "axes = axes.flatten()\n",
        "for i, ax in enumerate(axes):\n",
        "    image, label = train_dataset[i]\n",
        "    image = np.rollaxis(image, 0, 3)\n",
        "    image = image*std + mean\n",
        "    image = np.clip(image, 0., 1.)\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(f'label: {label}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-4c21980f71b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAHWCAYAAADzUtndAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJOEikSRJkiRJknCRSJIkSZIkScAfDLNBCSW6520AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x576 with 30 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7CsUn3fzDh3",
        "colab_type": "text"
      },
      "source": [
        "## 2.5 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWOi8ouNyZEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "history = pd.DataFrame()\n",
        "history2 = pd.DataFrame()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best = 1e10\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, mode='min', factor=0.7, verbose=True, min_lr=1e-5)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    train_model(epoch, optimizer, scheduler=None, history=history)\n",
        "    \n",
        "    loss = evaluate_model(epoch, scheduler=scheduler, history=history2)\n",
        "    \n",
        "    if loss < best:\n",
        "      best = loss\n",
        "      print(f'Saving best model...')\n",
        "      torch.save(model.state_dict(), f'model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRX3cOiByZJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFy1QUpYyZHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSgToDPsyJFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGHrrjw-yEUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}